{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tdbmnb-fwe3J","outputId":"e931e7b2-cc74-448a-c75a-094b3225df99"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: ultralytics in /usr/local/lib/python3.12/dist-packages (8.3.229)\n","Requirement already satisfied: numpy<=2.3.4,>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n","Requirement already satisfied: matplotlib<=3.10.7,>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n","Requirement already satisfied: opencv-python<=4.12.0.88,>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n","Requirement already satisfied: pillow<=12.0.0,>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n","Requirement already satisfied: pyyaml<=6.0.3,>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n","Requirement already satisfied: requests<=2.32.5,>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n","Requirement already satisfied: scipy<=1.16.3,>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n","Requirement already satisfied: torch<=2.9.1,>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n","Requirement already satisfied: torchvision<=0.24.1,>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n","Requirement already satisfied: psutil<=7.1.3,>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: polars<=1.35.2,>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n","Requirement already satisfied: ultralytics-thop<=2.0.18 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.18)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<=3.10.7,>=3.3.0->ultralytics) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib<=3.10.7,>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<=3.10.7,>=3.3.0->ultralytics) (4.60.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<=3.10.7,>=3.3.0->ultralytics) (1.4.9)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<=3.10.7,>=3.3.0->ultralytics) (25.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<=3.10.7,>=3.3.0->ultralytics) (3.2.5)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib<=3.10.7,>=3.3.0->ultralytics) (2.9.0.post0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<=2.32.5,>=2.23.0->ultralytics) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<=2.32.5,>=2.23.0->ultralytics) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<=2.32.5,>=2.23.0->ultralytics) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<=2.32.5,>=2.23.0->ultralytics) (2025.10.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<=2.9.1,>=1.8.0->ultralytics) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<=2.9.1,>=1.8.0->ultralytics) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<=2.9.1,>=1.8.0->ultralytics) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<=2.9.1,>=1.8.0->ultralytics) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<=2.9.1,>=1.8.0->ultralytics) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<=2.9.1,>=1.8.0->ultralytics) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch<=2.9.1,>=1.8.0->ultralytics) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<=2.9.1,>=1.8.0->ultralytics) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<=2.9.1,>=1.8.0->ultralytics) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<=2.9.1,>=1.8.0->ultralytics) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<=2.9.1,>=1.8.0->ultralytics) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<=2.9.1,>=1.8.0->ultralytics) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<=2.9.1,>=1.8.0->ultralytics) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<=2.9.1,>=1.8.0->ultralytics) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<=2.9.1,>=1.8.0->ultralytics) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<=2.9.1,>=1.8.0->ultralytics) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<=2.9.1,>=1.8.0->ultralytics) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<=2.9.1,>=1.8.0->ultralytics) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<=2.9.1,>=1.8.0->ultralytics) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<=2.9.1,>=1.8.0->ultralytics) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<=2.9.1,>=1.8.0->ultralytics) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<=2.9.1,>=1.8.0->ultralytics) (3.4.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib<=3.10.7,>=3.3.0->ultralytics) (1.17.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<=2.9.1,>=1.8.0->ultralytics) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<=2.9.1,>=1.8.0->ultralytics) (3.0.3)\n"]}],"source":["!pip install --upgrade ultralytics"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"sH8Xd4r6waNj","colab":{"base_uri":"https://localhost:8080/"},"outputId":"766e50c2-ef58-457d-8a29-64511d5d634f","executionInfo":{"status":"ok","timestamp":1763693363663,"user_tz":-60,"elapsed":157804,"user":{"displayName":"Lukáš Bageta","userId":"13443518161081904789"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] Video: ./video.mp4\n","       Resolution: 1920x1080, FPS: 60.04, Frames: 596\n","[INFO] Using device: cuda\n","[INFO] Processed 0/596 frames (0.0%)\n","[INFO] Processed 100/596 frames (16.8%)\n","[INFO] Processed 200/596 frames (33.6%)\n","[INFO] Processed 300/596 frames (50.3%)\n","[INFO] Processed 400/596 frames (67.1%)\n","[INFO] Processed 500/596 frames (83.9%)\n","[EVENT] Dangerous event #1 @ 20-11-2025 08:00:08 (pedestrian)\n","[INFO] Saved dangerous events JSON -> ./dangerous_events.json\n","[INFO] Saved time profile JSON -> ./time_profile.json\n","[INFO] Saved spatial heatmap image -> ./heatmap.png\n","[INFO] Total pedestrians (frame-level): 59\n","[INFO] Total vehicles (frame-level): 1039\n","[INFO] Annotated video saved to -> ./output_annotated.mp4\n"]}],"source":["# Dashcam Dangerous Event Analyzer\n","# --------------------------------\n","# Runnable in Google Colab. Uses Ultralytics YOLO11 for object detection + tracking,\n","# a simple speed estimation approach inspired by:\n","# https://docs.ultralytics.com/guides/speed-estimation/\n","# and ego-speed estimation from global optical flow.\n","#\n","# HOW TO USE IN COLAB:\n","# 1. Upload your dashcam video as \"video.mp4\" to the working directory, or change VIDEO_PATH below.\n","# 2. Run this cell.\n","# 3. Outputs:\n","#       - Annotated video: ./output_annotated.mp4\n","#       - Dangerous events JSON: ./dangerous_events.json\n","#       - Time profiling JSON: ./time_profile.json\n","#       - Spatial heatmap PNG: ./heatmap.png\n","\n","# =========================\n","# CONFIGURABLE CONSTANTS\n","# =========================\n","\n","VIDEO_PATH = \"./video.mp4\"      # default video location\n","OUTPUT_DIR = \"./\"               # default output directory\n","\n","OUTPUT_VIDEO_FILENAME = \"output_annotated.mp4\"\n","DANGEROUS_EVENTS_JSON = \"dangerous_events.json\"\n","TIME_PROFILE_JSON = \"time_profile.json\"\n","HEATMAP_IMAGE = \"heatmap.png\"\n","\n","# Ultralytics YOLO model (detection + tracking)\n","# (Make sure weights exist in Ultralytics; \"yolo11x.pt\" is the large YOLO11 detect model)\n","YOLO_MODEL_NAME = \"yolo11x.pt\"\n","\n","# Run YOLO only on every N-th frame for speed; intermediate frames use last detections\n","ANALYZE_EVERY_N_FRAMES = 3\n","\n","# Detection / tracking thresholds\n","CONF_THRESHOLD = 0.2\n","IOU_THRESHOLD = 0.1\n","\n","# Speed estimation configuration (approximate!)\n","# Meter-per-pixel strongly depends on camera calibration and setup.\n","METERS_PER_PIXEL = 0.05 * 0.5  # tweak for your dashcam\n","\n","# Ego vehicle speed estimation (optical-flow based)\n","EGO_SPEED_SMOOTHING = 0.5          # EMA smoothing factor [0..1]; closer to 1 = more smoothing\n","EGO_SPEED_MAX_KMH = 200.0          # clamp unrealistic ego speeds\n","# ROI used for optical flow (normalized coords: x1, y1, x2, y2)\n","# Adjust to roughly cover the road region in your dashcam.\n","EGO_FLOW_ROI_NORMALIZED = (0.3, 0.1, 0.7, 0.8)\n","\n","# Dangerous event configuration\n","REL_SPEED_THRESHOLD_KMH = 10.0      # relative speed threshold to trigger dangerous event\n","DANGER_COOLDOWN_SECONDS = 3.0       # minimum gap between two dangerous events\n","DANGER_OVERLAY_DURATION_SECONDS = 2.0  # how long to display \"DANGER\" overlay\n","\n","MIN_EVENT_CONFIDENCE = 0.4          # minimum detection confidence to consider for danger\n","\n","# Time profiling: number of seconds per bin\n","PROFILE_WINDOW_SECONDS = 5.0\n","\n","# Heatmap grid (coarse occupancy grid, not per-pixel)\n","HEATMAP_GRID_W = 40\n","HEATMAP_GRID_H = 24\n","\n","# Timestamp overlay configuration (DD-MM-YYYY hh:mm:ss)\n","VIDEO_START_DATETIME_STR = \"20-11-2025 8:00:00\"   # starting timestamp\n","TIMESTAMP_FORMAT = \"%d-%m-%Y %H:%M:%S\"\n","\n","# Alarm area polygon in NORMALIZED coordinates (relative to image width/height)\n","# This is a trapezoid roughly in front of the car, center of the frame.\n","# You can tune these values for your specific camera.\n","ALARM_POLYGON_NORMALIZED = [\n","    (0.43, 1.0),  # bottom-left\n","    (0.63, 1.0),  # bottom-right\n","    (0.47, 0.5),  # upper-right\n","    (0.59, 0.5),  # upper-left\n","]\n","\n","# Classes considered \"pedestrian\" or \"vehicle\" (COCO indexes)\n","PEDESTRIAN_CLASS_IDS = {0}  # person\n","VEHICLE_CLASS_IDS = {1, 2, 3, 5, 6, 7}  # bicycle, car, motorcycle, bus, train, truck\n","\n","# Whether to show OpenCV window (off for Colab)\n","SHOW_PREVIEW = False\n","\n","# =========================\n","# INSTALL DEPENDENCIES\n","# =========================\n","\n","import sys\n","import subprocess\n","\n","def install_if_missing(pkg: str):\n","    try:\n","        __import__(pkg.split(\"[\")[0].split(\">=\")[0])\n","    except ImportError:\n","        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg, \"-q\"])\n","\n","# ultralytics & OpenCV are needed\n","install_if_missing(\"ultralytics>=8.3.0\")\n","install_if_missing(\"opencv-python\")\n","\n","# =========================\n","# IMPORTS\n","# =========================\n","\n","import os\n","import json\n","import math\n","from collections import defaultdict\n","from dataclasses import dataclass\n","from datetime import datetime, timedelta\n","from typing import Dict, List, Tuple, Optional\n","\n","import cv2\n","import numpy as np\n","import torch\n","from ultralytics import YOLO\n","\n","# =========================\n","# DATA STRUCTURES\n","# =========================\n","\n","@dataclass\n","class DetectionRecord:\n","    track_id: Optional[int]\n","    cls_id: int\n","    obj_type: str  # 'pedestrian', 'vehicle', or 'other'\n","    conf: float\n","    bbox_xyxy: Tuple[float, float, float, float]\n","    center_xy: Tuple[float, float]\n","    speed_kmh: Optional[float]\n","    rel_speed_kmh: Optional[float]\n","    is_in_alarm_area: bool\n","    is_dangerous: bool\n","\n","\n","# =========================\n","# HELPERS\n","# =========================\n","\n","def get_device() -> str:\n","    \"\"\"Return 'cuda' if available, otherwise 'cpu'.\"\"\"\n","    if torch.cuda.is_available():\n","        return \"cuda\"\n","    return \"cpu\"\n","\n","\n","def build_alarm_polygon(image_width: int, image_height: int) -> np.ndarray:\n","    \"\"\"Convert normalized polygon coordinates into pixel coordinates.\"\"\"\n","    pts = []\n","    for x_norm, y_norm in ALARM_POLYGON_NORMALIZED:\n","        x = int(x_norm * image_width)\n","        y = int(y_norm * image_height)\n","        pts.append((x, y))\n","    polygon = np.array(pts, dtype=np.int32)\n","    return polygon\n","\n","\n","def map_class_to_type(cls_id: int) -> str:\n","    \"\"\"Map COCO class ID to our simplified types.\"\"\"\n","    if cls_id in PEDESTRIAN_CLASS_IDS:\n","        return \"pedestrian\"\n","    if cls_id in VEHICLE_CLASS_IDS:\n","        return \"vehicle\"\n","    return \"other\"\n","\n","\n","def point_inside_polygon(point: Tuple[float, float], polygon: np.ndarray) -> bool:\n","    \"\"\"Return True if point is inside or on the polygon.\"\"\"\n","    x, y = point\n","    res = cv2.pointPolygonTest(polygon, (float(x), float(y)), False)\n","    return res >= 0\n","\n","\n","def compute_speed_kmh(\n","    prev_center: Tuple[float, float],\n","    prev_frame_idx: int,\n","    cur_center: Tuple[float, float],\n","    cur_frame_idx: int,\n","    fps: float,\n","    meters_per_pixel: float,\n",") -> Optional[float]:\n","    \"\"\"Estimate object speed in km/h from motion between two frames.\n","\n","    Follows the principle described in Ultralytics' speed estimation guide:\n","    speed ~ (pixel_distance * meter_per_pixel) / delta_time * 3.6\n","    \"\"\"\n","    dt_frames = cur_frame_idx - prev_frame_idx\n","    if dt_frames <= 0 or fps <= 0:\n","        return None\n","    dt_seconds = dt_frames / fps\n","    dx = cur_center[0] - prev_center[0]\n","    dy = cur_center[1] - prev_center[1]\n","    pixel_dist = math.hypot(dx, dy)\n","    meters = pixel_dist * meters_per_pixel\n","    speed_m_per_s = meters / dt_seconds\n","    speed_kmh = speed_m_per_s * 3.6\n","    # Filter out unrealistically high speeds (likely tracking glitches)\n","    if not math.isfinite(speed_kmh) or speed_kmh < 0 or speed_kmh > 3000:\n","        return None\n","    return speed_kmh\n","\n","\n","def estimate_ego_speed_kmh(\n","    prev_gray: Optional[np.ndarray],\n","    cur_gray: np.ndarray,\n","    fps: float,\n","    meters_per_pixel: float,\n","    roi_norm: Optional[Tuple[float, float, float, float]] = None,\n",") -> Optional[float]:\n","    \"\"\"\n","    Estimate ego-vehicle speed from global optical flow between two frames.\n","    Uses dense Farneback flow and returns speed in km/h (very approximate).\n","    \"\"\"\n","    if prev_gray is None or cur_gray is None or fps <= 0:\n","        return None\n","\n","    # Optional ROI focusing on the road area\n","    if roi_norm is not None:\n","        h, w = prev_gray.shape[:2]\n","        x1 = int(roi_norm[0] * w)\n","        y1 = int(roi_norm[1] * h)\n","        x2 = int(roi_norm[2] * w)\n","        y2 = int(roi_norm[3] * h)\n","        prev = prev_gray[y1:y2, x1:x2]\n","        cur = cur_gray[y1:y2, x1:x2]\n","    else:\n","        prev = prev_gray\n","        cur = cur_gray\n","\n","    if prev.size == 0 or cur.size == 0:\n","        return None\n","\n","    # Dense optical flow\n","    flow = cv2.calcOpticalFlowFarneback(\n","        prev, cur, None,\n","        0.5,   # pyr_scale\n","        3,     # levels\n","        15,    # winsize\n","        3,     # iterations\n","        5,     # poly_n\n","        1.2,   # poly_sigma\n","        0      # flags\n","    )\n","\n","    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n","\n","    mag_flat = mag.reshape(-1)\n","    if mag_flat.size == 0:\n","        return None\n","\n","    # Robust central value of motion (median)\n","    px_per_frame = float(np.median(mag_flat))\n","    px_per_s = px_per_frame * fps\n","    speed_m_s = px_per_s * meters_per_pixel\n","    speed_kmh = speed_m_s * 3.6\n","\n","    if not math.isfinite(speed_kmh) or speed_kmh < 0:\n","        return None\n","\n","    # Clamp unrealistic optical-flow spikes\n","    if speed_kmh > EGO_SPEED_MAX_KMH:\n","        speed_kmh = EGO_SPEED_MAX_KMH\n","\n","    # Very small values are likely noise\n","    if speed_kmh < 1.0:\n","        return 0.0\n","\n","    return speed_kmh\n","\n","\n","def draw_timestamp_and_speed(\n","    frame: np.ndarray,\n","    timestamp_str: str,\n","    ego_speed_kmh: float,\n",") -> None:\n","    \"\"\"Draw timestamp and vehicle speed in the top-right corner.\"\"\"\n","    h, w = frame.shape[:2]\n","    font = cv2.FONT_HERSHEY_SIMPLEX\n","    font_scale = 0.6\n","    thickness = 2\n","\n","    text_ts = timestamp_str\n","    text_speed = f\"Speed: {ego_speed_kmh:.1f} km/h\"\n","\n","    # Compute text widths\n","    (ts_w, ts_h), _ = cv2.getTextSize(text_ts, font, font_scale, thickness)\n","    (sp_w, sp_h), _ = cv2.getTextSize(text_speed, font, font_scale, thickness)\n","\n","    margin = 10\n","    x_ts = w - ts_w - margin\n","    y_ts = margin + ts_h\n","\n","    x_sp = w - sp_w - margin\n","    y_sp = y_ts + sp_h + 5\n","\n","    # Background rectangles\n","    pad = 5\n","    cv2.rectangle(\n","        frame,\n","        (min(x_ts, x_sp) - pad, margin),\n","        (w - margin + pad, y_sp + pad),\n","        (0, 0, 0),\n","        thickness=-1,\n","    )\n","\n","    # Timestamp\n","    cv2.putText(\n","        frame,\n","        text_ts,\n","        (x_ts, y_ts),\n","        font,\n","        font_scale,\n","        (255, 255, 255),\n","        thickness,\n","        cv2.LINE_AA,\n","    )\n","\n","    # Speed\n","    cv2.putText(\n","        frame,\n","        text_speed,\n","        (x_sp, y_sp),\n","        font,\n","        font_scale,\n","        (0, 255, 255),\n","        thickness,\n","        cv2.LINE_AA,\n","    )\n","\n","\n","def draw_alarm_polygon(frame: np.ndarray, polygon: np.ndarray, highlight: bool = False) -> None:\n","    \"\"\"Draw the alarm area polygon on the frame.\"\"\"\n","    color = (0, 255, 255) if not highlight else (0, 0, 255)  # yellow vs red\n","    cv2.polylines(frame, [polygon], isClosed=True, color=color, thickness=2)\n","\n","\n","def draw_detections(\n","    frame: np.ndarray,\n","    detections: List[DetectionRecord],\n","    class_names: Dict[int, str],\n",") -> None:\n","    \"\"\"Draw detection bounding boxes, labels, and speed on the frame.\"\"\"\n","    for det in detections:\n","        x1, y1, x2, y2 = map(int, det.bbox_xyxy)\n","        color = (0, 255, 0)  # default green\n","        if det.obj_type == \"pedestrian\":\n","            color = (255, 255, 0)  # cyan-like\n","        if det.is_dangerous:\n","            color = (0, 0, 255)  # red for danger\n","\n","        # Draw bounding box\n","        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n","\n","        # Label text\n","        name = class_names.get(det.cls_id, str(det.cls_id))\n","        label_bits = [name]\n","        if det.track_id is not None:\n","            label_bits.append(f\"#{det.track_id}\")\n","        if det.speed_kmh is not None:\n","            label_bits.append(f\"{det.speed_kmh:.1f} km/h\")\n","        label = \" \".join(label_bits)\n","\n","        font = cv2.FONT_HERSHEY_SIMPLEX\n","        font_scale = 0.5\n","        thickness = 1\n","        (text_w, text_h), _ = cv2.getTextSize(label, font, font_scale, thickness)\n","        cv2.rectangle(\n","            frame,\n","            (x1, y1 - text_h - 4),\n","            (x1 + text_w + 4, y1),\n","            (0, 0, 0),\n","            thickness=-1,\n","        )\n","        cv2.putText(\n","            frame,\n","            label,\n","            (x1 + 2, y1 - 4),\n","            font,\n","            font_scale,\n","            (255, 255, 255),\n","            thickness,\n","            cv2.LINE_AA,\n","        )\n","\n","\n","def draw_danger_overlay(frame: np.ndarray) -> None:\n","    \"\"\"Draw a big 'DANGEROUS EVENT' overlay in the middle/top of the frame.\"\"\"\n","    h, w = frame.shape[:2]\n","    text = \"DANGEROUS EVENT\"\n","    font = cv2.FONT_HERSHEY_SIMPLEX\n","    font_scale = 1.2\n","    thickness = 3\n","    (text_w, text_h), _ = cv2.getTextSize(text, font, font_scale, thickness)\n","    x = (w - text_w) // 2\n","    y = int(0.15 * h)\n","\n","    cv2.rectangle(\n","        frame,\n","        (x - 10, y - text_h - 10),\n","        (x + text_w + 10, y + 10),\n","        (0, 0, 255),\n","        thickness=-1,\n","    )\n","    cv2.putText(\n","        frame,\n","        text,\n","        (x, y),\n","        font,\n","        font_scale,\n","        (255, 255, 255),\n","        thickness,\n","        cv2.LINE_AA,\n","    )\n","\n","\n","# =========================\n","# MAIN ANALYSIS PIPELINE\n","# =========================\n","\n","def main():\n","    # Prepare paths\n","    os.makedirs(OUTPUT_DIR, exist_ok=True)\n","    output_video_path = os.path.join(OUTPUT_DIR, OUTPUT_VIDEO_FILENAME)\n","    events_json_path = os.path.join(OUTPUT_DIR, DANGEROUS_EVENTS_JSON)\n","    time_profile_path = os.path.join(OUTPUT_DIR, TIME_PROFILE_JSON)\n","    heatmap_path = os.path.join(OUTPUT_DIR, HEATMAP_IMAGE)\n","\n","    # Parse start datetime\n","    try:\n","        start_datetime = datetime.strptime(VIDEO_START_DATETIME_STR, TIMESTAMP_FORMAT)\n","    except ValueError:\n","        print(f\"[WARN] Could not parse VIDEO_START_DATETIME_STR '{VIDEO_START_DATETIME_STR}'.\")\n","        print(\"       Falling back to current time as start.\")\n","        start_datetime = datetime.now()\n","\n","    # Open video\n","    cap = cv2.VideoCapture(VIDEO_PATH)\n","    if not cap.isOpened():\n","        raise RuntimeError(f\"Could not open video: {VIDEO_PATH}\")\n","\n","    frame_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","    frame_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","    fps = cap.get(cv2.CAP_PROP_FPS) or 0.0\n","    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","\n","    if fps <= 0:\n","        print(\"[WARN] Video FPS not detected; assuming 30 FPS.\")\n","        fps = 30.0\n","\n","    print(f\"[INFO] Video: {VIDEO_PATH}\")\n","    print(f\"       Resolution: {frame_w}x{frame_h}, FPS: {fps:.2f}, Frames: {total_frames}\")\n","\n","    # Prepare writer\n","    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n","    writer = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_w, frame_h))\n","\n","    # Build alarm polygon\n","    alarm_polygon_px = build_alarm_polygon(frame_w, frame_h)\n","\n","    # Load YOLO model\n","    device = get_device()\n","    print(f\"[INFO] Using device: {device}\")\n","    model = YOLO(YOLO_MODEL_NAME)\n","    # (model.to(device) is usually not required, but harmless)\n","    try:\n","        model.to(device)\n","    except Exception:\n","        # Some Ultralytics versions don't expose .to on YOLO wrapper; rely on device=... instead\n","        pass\n","\n","    class_names = model.model.names if hasattr(model, \"model\") else model.names\n","\n","    # Tracking state for speed estimation\n","    # track_id -> (last_frame_idx, (cx, cy))\n","    last_track_positions: Dict[int, Tuple[int, Tuple[float, float]]] = {}\n","\n","    # Statistics\n","    dangerous_events: List[dict] = []\n","    next_event_id = 1\n","    last_event_time_sec: Optional[float] = None\n","    danger_overlay_until_sec: float = -1.0\n","\n","    # Time profiling: window_index -> detection count\n","    time_profile_counts: Dict[int, int] = defaultdict(int)\n","\n","    # Heatmap accumulator\n","    heatmap = np.zeros((HEATMAP_GRID_H, HEATMAP_GRID_W), dtype=np.float32)\n","\n","    # Object counts (per-frame counts – not unique track-based)\n","    total_pedestrians = 0\n","    total_vehicles = 0\n","\n","    # Cache latest detections for intermediate frames\n","    cached_detections: List[DetectionRecord] = []\n","\n","    # Ego-speed estimation state\n","    prev_gray: Optional[np.ndarray] = None\n","    ego_speed_kmh: float = 0.0\n","\n","    frame_idx = 0\n","    while True:\n","        success, frame = cap.read()\n","        if not success:\n","            break\n","\n","        # --- Ego speed from optical flow ---\n","        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","        estimated_ego_speed = estimate_ego_speed_kmh(\n","            prev_gray,\n","            gray,\n","            fps,\n","            METERS_PER_PIXEL,\n","            roi_norm=EGO_FLOW_ROI_NORMALIZED,\n","        )\n","        if estimated_ego_speed is not None:\n","            # Exponential moving average smoothing\n","            ego_speed_kmh = (\n","                EGO_SPEED_SMOOTHING * ego_speed_kmh\n","                + (1.0 - EGO_SPEED_SMOOTHING) * estimated_ego_speed\n","            )\n","        prev_gray = gray\n","        # --- end ego speed ---\n","\n","        current_time_sec = frame_idx / fps\n","        timestamp_str = (start_datetime + timedelta(seconds=current_time_sec)).strftime(TIMESTAMP_FORMAT)\n","\n","        is_analysis_frame = (frame_idx % ANALYZE_EVERY_N_FRAMES == 0)\n","\n","        # ========================\n","        # RUN VISION MODEL PERIODICALLY\n","        # ========================\n","        if is_analysis_frame:\n","            # YOLO tracking call (persist=True keeps track IDs across frames)\n","            results = model.track(\n","                frame,\n","                conf=CONF_THRESHOLD,\n","                iou=IOU_THRESHOLD,\n","                device=device,\n","                persist=True,\n","                verbose=False,\n","            )\n","            result = results[0]\n","\n","            new_detections: List[DetectionRecord] = []\n","\n","            if result.boxes is not None and len(result.boxes) > 0:\n","                boxes_xyxy = result.boxes.xyxy.cpu().numpy()\n","                cls_ids = result.boxes.cls.int().cpu().numpy()\n","                confs = result.boxes.conf.cpu().numpy()\n","                if result.boxes.id is not None:\n","                    track_ids = result.boxes.id.int().cpu().tolist()\n","                else:\n","                    track_ids = [None] * len(boxes_xyxy)\n","\n","                for bbox, cls_id, conf, tid in zip(boxes_xyxy, cls_ids, confs, track_ids):\n","                    if conf < CONF_THRESHOLD:\n","                        continue\n","\n","                    x1, y1, x2, y2 = bbox\n","                    cx = 0.5 * (x1 + x2)\n","                    cy = 0.5 * (y1 + y2)\n","                    center = (cx, cy)\n","\n","                    obj_type = map_class_to_type(cls_id)\n","\n","                    # Update counts (simple per-frame counts)\n","                    if obj_type == \"pedestrian\":\n","                        total_pedestrians += 1\n","                    elif obj_type == \"vehicle\":\n","                        total_vehicles += 1\n","\n","                    # Speed estimation using previous track position\n","                    speed_kmh = None\n","                    if tid is not None:\n","                        if tid in last_track_positions:\n","                            prev_frame_idx, prev_center = last_track_positions[tid]\n","                            speed_kmh = compute_speed_kmh(\n","                                prev_center,\n","                                prev_frame_idx,\n","                                center,\n","                                frame_idx,\n","                                fps,\n","                                METERS_PER_PIXEL,\n","                            )\n","                        # Update last position\n","                        last_track_positions[tid] = (frame_idx, center)\n","\n","                    # Relative speed vs ego vehicle (estimated from optical flow)\n","                    rel_speed_kmh = None\n","                    if speed_kmh is not None:\n","                        rel_speed_kmh = abs(speed_kmh - ego_speed_kmh)\n","\n","                    # Check if inside alarm area\n","                    is_in_alarm_area = point_inside_polygon(center, alarm_polygon_px)\n","\n","                    # Dangerous event?\n","                    is_dangerous = False\n","                    if (\n","                        obj_type in {\"pedestrian\", \"vehicle\"}\n","                        and is_in_alarm_area\n","                        and rel_speed_kmh is not None\n","                        and rel_speed_kmh >= REL_SPEED_THRESHOLD_KMH\n","                        and conf >= MIN_EVENT_CONFIDENCE\n","                    ):\n","                        # Enforce cooldown\n","                        if last_event_time_sec is None or (\n","                            current_time_sec - last_event_time_sec >= DANGER_COOLDOWN_SECONDS\n","                        ):\n","                            is_dangerous = True\n","                            # Log event\n","                            event_timestamp = (start_datetime + timedelta(seconds=current_time_sec)).strftime(\n","                                TIMESTAMP_FORMAT\n","                            )\n","                            events_entry = {\n","                                \"id\": next_event_id,\n","                                \"timestamp\": event_timestamp,\n","                                \"type\": obj_type,\n","                                \"confidence\": float(conf),\n","                                \"ego_speed_kmh\": float(ego_speed_kmh),\n","                                \"object_speed_kmh\": float(speed_kmh) if speed_kmh is not None else None,\n","                                \"relative_speed_kmh\": float(rel_speed_kmh),\n","                            }\n","                            dangerous_events.append(events_entry)\n","                            print(f\"[EVENT] Dangerous event #{next_event_id} @ {event_timestamp} ({obj_type})\")\n","                            next_event_id += 1\n","                            last_event_time_sec = current_time_sec\n","                            danger_overlay_until_sec = current_time_sec + DANGER_OVERLAY_DURATION_SECONDS\n","\n","                    det_rec = DetectionRecord(\n","                        track_id=tid,\n","                        cls_id=int(cls_id),\n","                        obj_type=obj_type,\n","                        conf=float(conf),\n","                        bbox_xyxy=(float(x1), float(y1), float(x2), float(y2)),\n","                        center_xy=center,\n","                        speed_kmh=speed_kmh,\n","                        rel_speed_kmh=rel_speed_kmh,\n","                        is_in_alarm_area=is_in_alarm_area,\n","                        is_dangerous=is_dangerous,\n","                    )\n","                    new_detections.append(det_rec)\n","\n","                # Update heatmap & time profile using new detections\n","                for det in new_detections:\n","                    cx, cy = det.center_xy\n","                    gx = int(np.clip(cx / frame_w * HEATMAP_GRID_W, 0, HEATMAP_GRID_W - 1))\n","                    gy = int(np.clip(cy / frame_h * HEATMAP_GRID_H, 0, HEATMAP_GRID_H - 1))\n","                    heatmap[gy, gx] += 1.0\n","\n","                window_idx = int(current_time_sec / PROFILE_WINDOW_SECONDS)\n","                time_profile_counts[window_idx] += len(new_detections)\n","\n","            cached_detections = new_detections\n","\n","        # ========================\n","        # OVERLAY VISUALS (for every frame)\n","        # ========================\n","\n","        # Copy frame for drawing\n","        annotated_frame = frame.copy()\n","\n","        # Draw alarm polygon (highlighted if a danger has just been detected on this frame)\n","        highlight_polygon = any(det.is_dangerous for det in cached_detections)\n","        draw_alarm_polygon(annotated_frame, alarm_polygon_px, highlight=highlight_polygon)\n","\n","        # Draw cached detections (latest analyzed frame)\n","        draw_detections(annotated_frame, cached_detections, class_names)\n","\n","        # Timestamp and ego speed (estimated)\n","        draw_timestamp_and_speed(annotated_frame, timestamp_str, ego_speed_kmh)\n","\n","        # Danger overlay (if within overlay duration)\n","        if current_time_sec <= danger_overlay_until_sec:\n","            draw_danger_overlay(annotated_frame)\n","\n","        # Write frame\n","        writer.write(annotated_frame)\n","\n","        # Optional preview window (typically off in Colab)\n","        if SHOW_PREVIEW:\n","            cv2.imshow(\"Annotated\", annotated_frame)\n","            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n","                break\n","\n","        # Progress print\n","        if frame_idx % 100 == 0:\n","            if total_frames > 0:\n","                pct = 100.0 * frame_idx / total_frames\n","                print(f\"[INFO] Processed {frame_idx}/{total_frames} frames ({pct:.1f}%)\")\n","            else:\n","                print(f\"[INFO] Processed {frame_idx} frames\")\n","\n","        frame_idx += 1\n","\n","    # Cleanup\n","    cap.release()\n","    writer.release()\n","    if SHOW_PREVIEW:\n","        cv2.destroyAllWindows()\n","\n","    # ========================\n","    # SAVE OUTPUTS\n","    # ========================\n","\n","    # Dangerous events JSON\n","    with open(events_json_path, \"w\", encoding=\"utf-8\") as f:\n","        json.dump(dangerous_events, f, indent=2)\n","    print(f\"[INFO] Saved dangerous events JSON -> {events_json_path}\")\n","\n","    # Time profile JSON (objects per time window)\n","    profile_list = []\n","    for window_idx, count in sorted(time_profile_counts.items()):\n","        window_start_sec = window_idx * PROFILE_WINDOW_SECONDS\n","        window_end_sec = (window_idx + 1) * PROFILE_WINDOW_SECONDS\n","        window_start_ts = (start_datetime + timedelta(seconds=window_start_sec)).strftime(TIMESTAMP_FORMAT)\n","        window_end_ts = (start_datetime + timedelta(seconds=window_end_sec)).strftime(TIMESTAMP_FORMAT)\n","        profile_list.append(\n","            {\n","                \"window_index\": int(window_idx),\n","                \"window_start_timestamp\": window_start_ts,\n","                \"window_end_timestamp\": window_end_ts,\n","                \"detections\": int(count),\n","                \"detections_per_second\": float(count / PROFILE_WINDOW_SECONDS),\n","            }\n","        )\n","\n","    with open(time_profile_path, \"w\", encoding=\"utf-8\") as f:\n","        json.dump(profile_list, f, indent=2)\n","    print(f\"[INFO] Saved time profile JSON -> {time_profile_path}\")\n","\n","    # Heatmap image\n","    if heatmap.max() > 0:\n","        heatmap_norm = (heatmap / heatmap.max() * 255.0).astype(np.uint8)\n","    else:\n","        heatmap_norm = heatmap.astype(np.uint8)\n","\n","    heatmap_resized = cv2.resize(\n","        heatmap_norm, (frame_w, frame_h), interpolation=cv2.INTER_NEAREST\n","    )\n","    heatmap_color = cv2.applyColorMap(heatmap_resized, cv2.COLORMAP_JET)\n","    cv2.imwrite(heatmap_path, heatmap_color)\n","    print(f\"[INFO] Saved spatial heatmap image -> {heatmap_path}\")\n","\n","    print(f\"[INFO] Total pedestrians (frame-level): {total_pedestrians}\")\n","    print(f\"[INFO] Total vehicles (frame-level): {total_vehicles}\")\n","    print(f\"[INFO] Annotated video saved to -> {output_video_path}\")\n","\n","\n","if __name__ == \"__main__\":\n","    main()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_YAPWfVwwolB"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}